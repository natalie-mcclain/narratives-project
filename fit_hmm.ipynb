{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d936e5-dd5c-4ca3-8a0a-1987834a7587",
   "metadata": {},
   "source": [
    "# HMM Model Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d713e84-3569-46cb-85b8-d736aae5b3f5",
   "metadata": {},
   "source": [
    "Now that we have network-level signal, temporally trimmed data for all our subjects we can fit the HMM model! First we're going to try 10 states to see how that looks...\n",
    "Random note: Before doing this I also confirmed that all the networks were ordered correctly across subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f98ab1d-14cb-42b4-8e48-60b155f2402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "assert torch.cuda.is_available(), \"No GPU detected!\"\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ad30ae-3669-4abf-99f8-4820a728aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hmmlearn import hmm\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba8e6e54-8853-421b-b5d0-c7d6f2d708aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loaded 75 subjects\n",
      "  Subject 0: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 1: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 2: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 3: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 4: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 5: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 6: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 7: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 8: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 9: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 10: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 11: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 12: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 13: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 14: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 15: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 16: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 17: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 18: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 19: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 20: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 21: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 22: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 23: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 24: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 25: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 26: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 27: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 28: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 29: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 30: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 31: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 32: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 33: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 34: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 35: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 36: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 37: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 38: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 39: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 40: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 41: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 42: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 43: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 44: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 45: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 46: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 47: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 48: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 49: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 50: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 51: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 52: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 53: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 54: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 55: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 56: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 57: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 58: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 59: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 60: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 61: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 62: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 63: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 64: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 65: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 66: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 67: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 68: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 69: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 70: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 71: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 72: shape=(279, 14), mean=0.0000, std=1.0000\n",
      "  Subject 73: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "  Subject 74: shape=(279, 14), mean=-0.0000, std=1.0000\n",
      "Fitting HMM for k=10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -261773.45078789             +nan\n",
      "         2 -243146.74264435  +18626.70814354\n",
      "         3 -237303.65747338   +5843.08517097\n",
      "         4 -234604.49431960   +2699.16315378\n",
      "         5 -232967.14240323   +1637.35191637\n",
      "         6 -231913.55922860   +1053.58317463\n",
      "         7 -231257.16188108    +656.39734751\n",
      "         8 -230785.06232089    +472.09956020\n",
      "         9 -230388.50810904    +396.55421184\n",
      "        10 -230014.01146869    +374.49664036\n",
      "        11 -229698.91408528    +315.09738341\n",
      "        12 -229444.37448840    +254.53959687\n",
      "        13 -229234.42148868    +209.95299972\n",
      "        14 -229050.44304858    +183.97844010\n",
      "        15 -228903.42965319    +147.01339538\n",
      "        16 -228793.74347897    +109.68617422\n",
      "        17 -228703.66688843     +90.07659054\n",
      "        18 -228621.55956273     +82.10732570\n",
      "        19 -228540.56614218     +80.99342056\n",
      "        20 -228458.54194027     +82.02420191\n",
      "        21 -228370.00373741     +88.53820285\n",
      "        22 -228275.38310135     +94.62063606\n",
      "        23 -228173.27684689    +102.10625446\n",
      "        24 -228059.71652978    +113.56031712\n",
      "        25 -227931.12791238    +128.58861739\n",
      "        26 -227794.95213764    +136.17577474\n",
      "        27 -227669.81655825    +125.13557939\n",
      "        28 -227559.42027261    +110.39628564\n",
      "        29 -227457.10004038    +102.32023223\n",
      "        30 -227358.18999874     +98.91004164\n",
      "        31 -227220.02069063    +138.16930810\n",
      "        32 -227073.59134735    +146.42934329\n",
      "        33 -226950.52984200    +123.06150535\n",
      "        34 -226837.17438434    +113.35545766\n",
      "        35 -226729.34303070    +107.83135364\n",
      "        36 -226633.66685387     +95.67617683\n",
      "        37 -226542.80369156     +90.86316231\n",
      "        38 -226464.18731870     +78.61637286\n",
      "        39 -226361.62984803    +102.55747068\n",
      "        40 -226265.29203772     +96.33781030\n",
      "        41 -226163.03268415    +102.25935357\n",
      "        42 -226054.48897832    +108.54370584\n",
      "        43 -225905.41789004    +149.07108828\n",
      "        44 -225674.20098207    +231.21690797\n",
      "        45 -225459.77036045    +214.43062162\n",
      "        46 -225324.10054232    +135.66981813\n",
      "        47 -225230.04414552     +94.05639680\n",
      "        48 -225140.82135007     +89.22279545\n",
      "        49 -225044.59831798     +96.22303209\n",
      "        50 -224917.19194147    +127.40637651\n",
      "        51 -224733.66312068    +183.52882079\n",
      "        52 -224539.66840813    +193.99471255\n",
      "        53 -224366.94863383    +172.71977430\n",
      "        54 -224222.23475575    +144.71387808\n",
      "        55 -224104.76359774    +117.47115802\n",
      "        56 -224009.76227065     +95.00132709\n",
      "        57 -223924.85726850     +84.90500215\n",
      "        58 -223862.47281259     +62.38445591\n",
      "        59 -223807.93681702     +54.53599557\n",
      "        60 -223754.35173545     +53.58508157\n",
      "        61 -223702.30243692     +52.04929853\n",
      "        62 -223651.70688522     +50.59555170\n",
      "        63 -223601.88206437     +49.82482085\n",
      "        64 -223556.05069758     +45.83136678\n",
      "        65 -223516.51839939     +39.53229819\n",
      "        66 -223484.72206325     +31.79633614\n",
      "        67 -223457.11371584     +27.60834741\n",
      "        68 -223431.88362344     +25.23009240\n",
      "        69 -223411.49906613     +20.38455731\n",
      "        70 -223397.66296885     +13.83609728\n",
      "        71 -223386.65870080     +11.00426805\n",
      "        72 -223376.88387250      +9.77482830\n",
      "        73 -223365.75433468     +11.12953782\n",
      "        74 -223352.69107511     +13.06325956\n",
      "        75 -223341.18858280     +11.50249232\n",
      "        76 -223329.86909756     +11.31948524\n",
      "        77 -223316.36697967     +13.50211789\n",
      "        78 -223302.14543982     +14.22153985\n",
      "        79 -223291.37145756     +10.77398226\n",
      "        80 -223280.54635451     +10.82510305\n",
      "        81 -223266.41847191     +14.12788260\n",
      "        82 -223248.97906286     +17.43940905\n",
      "        83 -223219.03076474     +29.94829812\n",
      "        84 -223187.83348489     +31.19727985\n",
      "        85 -223165.80513485     +22.02835004\n",
      "        86 -223150.30222702     +15.50290783\n",
      "        87 -223138.66338879     +11.63883823\n",
      "        88 -223129.54124000      +9.12214879\n",
      "        89 -223121.19443559      +8.34680442\n",
      "        90 -223112.11465205      +9.07978353\n",
      "        91 -223103.07286507      +9.04178699\n",
      "        92 -223095.20329607      +7.86956900\n",
      "        93 -223087.63044614      +7.57284993\n",
      "        94 -223080.04797498      +7.58247116\n",
      "        95 -223072.47270254      +7.57527245\n",
      "        96 -223064.77651553      +7.69618701\n",
      "        97 -223056.67816079      +8.09835474\n",
      "        98 -223048.10714461      +8.57101618\n",
      "        99 -223038.87731904      +9.22982556\n",
      "       100 -223027.77111011     +11.10620893\n",
      "       101 -223015.63570860     +12.13540151\n",
      "       102 -223003.22546149     +12.41024710\n",
      "       103 -222989.59403138     +13.63143011\n",
      "       104 -222974.69031062     +14.90372077\n",
      "       105 -222957.60693356     +17.08337706\n",
      "       106 -222937.07064111     +20.53629244\n",
      "       107 -222910.56504793     +26.50559318\n",
      "       108 -222873.38003658     +37.18501135\n",
      "       109 -222818.79452112     +54.58551547\n",
      "       110 -222738.89372301     +79.90079811\n",
      "       111 -222627.21412339    +111.67959962\n",
      "       112 -222488.39227822    +138.82184517\n",
      "       113 -222344.66787759    +143.72440063\n",
      "       114 -222221.82489088    +122.84298671\n",
      "       115 -222134.86695862     +86.95793226\n",
      "       116 -222077.41066498     +57.45629364\n",
      "       117 -222034.23711188     +43.17355310\n",
      "       118 -221996.92365912     +37.31345276\n",
      "       119 -221961.91445948     +35.00919964\n",
      "       120 -221929.66244532     +32.25201415\n",
      "       121 -221902.88359237     +26.77885296\n",
      "       122 -221882.61379005     +20.26980232\n",
      "       123 -221866.85774205     +15.75604800\n",
      "       124 -221851.69842780     +15.15931425\n",
      "       125 -221834.85664183     +16.84178597\n",
      "       126 -221817.49343527     +17.36320656\n",
      "       127 -221801.74965035     +15.74378491\n",
      "       128 -221787.84261198     +13.90703838\n",
      "       129 -221775.81856493     +12.02404704\n",
      "       130 -221766.62340078      +9.19516416\n",
      "       131 -221758.71612688      +7.90727390\n",
      "       132 -221751.72046474      +6.99566214\n",
      "       133 -221745.19529773      +6.52516700\n",
      "       134 -221738.53645285      +6.65884489\n",
      "       135 -221731.65408940      +6.88236344\n",
      "       136 -221723.85492597      +7.79916344\n",
      "       137 -221714.04129518      +9.81363079\n",
      "       138 -221702.37772432     +11.66357085\n",
      "       139 -221689.00196012     +13.37576420\n",
      "       140 -221673.59566453     +15.40629559\n",
      "       141 -221657.22599728     +16.36966725\n",
      "       142 -221643.56104791     +13.66494937\n",
      "       143 -221633.47042939     +10.09061852\n",
      "       144 -221625.85936602      +7.61106338\n",
      "       145 -221619.47689113      +6.38247489\n",
      "       146 -221612.87548983      +6.60140130\n",
      "       147 -221607.02144143      +5.85404840\n",
      "       148 -221602.20998528      +4.81145615\n",
      "       149 -221599.48767642      +2.72230886\n",
      "       150 -221597.51259283      +1.97508360\n",
      "       151 -221595.85969107      +1.65290176\n",
      "       152 -221594.43145340      +1.42823767\n",
      "       153 -221593.20729701      +1.22415639\n",
      "       154 -221592.17277738      +1.03451963\n",
      "       155 -221591.29181994      +0.88095744\n",
      "       156 -221590.52726291      +0.76455703\n",
      "       157 -221589.85260996      +0.67465295\n",
      "       158 -221589.24770937      +0.60490059\n",
      "       159 -221588.69589863      +0.55181074\n",
      "       160 -221588.18399483      +0.51190380\n",
      "       161 -221587.70299336      +0.48100147\n",
      "       162 -221587.24821076      +0.45478260\n",
      "       163 -221586.81788461      +0.43032616\n",
      "       164 -221586.41076414      +0.40712047\n",
      "       165 -221586.02445170      +0.38631244\n",
      "       166 -221585.65489112      +0.36956059\n",
      "       167 -221585.29606111      +0.35883001\n",
      "       168 -221584.93936986      +0.35669125\n",
      "       169 -221584.57256648      +0.36680338\n",
      "       170 -221584.17752313      +0.39504335\n",
      "       171 -221583.72603376      +0.45148936\n",
      "       172 -221583.17573930      +0.55029447\n",
      "       173 -221582.48319256      +0.69254673\n",
      "       174 -221581.66216727      +0.82102529\n",
      "       175 -221580.80996005      +0.85220722\n",
      "       176 -221579.99203415      +0.81792590\n",
      "       177 -221579.18530440      +0.80672976\n",
      "       178 -221578.33129154      +0.85401286\n",
      "       179 -221577.37687314      +0.95441840\n",
      "       180 -221576.31425505      +1.06261809\n",
      "       181 -221575.22148338      +1.09277167\n",
      "       182 -221574.18426759      +1.03721579\n",
      "       183 -221573.21231920      +0.97194839\n",
      "       184 -221572.22387263      +0.98844657\n",
      "       185 -221570.94375455      +1.28011808\n",
      "       186 -221569.39036862      +1.55338593\n",
      "       187 -221567.98981912      +1.40054950\n",
      "       188 -221566.50334067      +1.48647845\n",
      "       189 -221564.80981466      +1.69352601\n",
      "       190 -221562.97895466      +1.83085999\n",
      "       191 -221561.19965547      +1.77929919\n",
      "       192 -221559.68120149      +1.51845399\n",
      "       193 -221558.41621243      +1.26498906\n",
      "       194 -221557.32008459      +1.09612784\n",
      "       195 -221556.34254823      +0.97753636\n",
      "       196 -221555.45272330      +0.88982493\n",
      "       197 -221554.62329795      +0.82942535\n",
      "       198 -221553.82260456      +0.80069339\n",
      "       199 -221553.00696118      +0.81564338\n",
      "       200 -221552.12934743      +0.87761375\n",
      "       201 -221551.21368010      +0.91566734\n",
      "       202 -221550.36585810      +0.84782199\n",
      "       203 -221549.60669409      +0.75916401\n",
      "       204 -221548.91481195      +0.69188214\n",
      "       205 -221548.28621055      +0.62860140\n",
      "       206 -221547.70984004      +0.57637051\n",
      "       207 -221547.16553406      +0.54430598\n",
      "       208 -221546.62868077      +0.53685328\n",
      "       209 -221546.06794771      +0.56073307\n",
      "       210 -221545.44745242      +0.62049529\n",
      "       211 -221544.76062726      +0.68682516\n",
      "       212 -221544.07161729      +0.68900997\n",
      "       213 -221543.44181502      +0.62980228\n",
      "       214 -221542.86871106      +0.57310396\n",
      "       215 -221542.33037429      +0.53833678\n",
      "       216 -221541.80533147      +0.52504282\n",
      "       217 -221541.26943606      +0.53589540\n",
      "       218 -221540.68068836      +0.58874770\n",
      "       219 -221539.90829687      +0.77239149\n",
      "       220 -221538.47891029      +1.42938659\n",
      "       221 -221535.84610660      +2.63280369\n",
      "       222 -221533.42901723      +2.41708937\n",
      "       223 -221532.10968213      +1.31933510\n",
      "       224 -221531.34018474      +0.76949739\n",
      "       225 -221530.81053283      +0.52965192\n",
      "       226 -221530.40390601      +0.40662682\n",
      "       227 -221530.06975664      +0.33414936\n",
      "       228 -221529.78126076      +0.28849589\n",
      "       229 -221529.52201231      +0.25924845\n",
      "       230 -221529.28089875      +0.24111356\n",
      "       231 -221529.04990538      +0.23099337\n",
      "       232 -221528.82326996      +0.22663542\n",
      "       233 -221528.59737550      +0.22589445\n",
      "       234 -221528.37100165      +0.22637385\n",
      "       235 -221528.14546780      +0.22553386\n",
      "       236 -221527.92414124      +0.22132655\n",
      "       237 -221527.71117396      +0.21296728\n",
      "       238 -221527.51004254      +0.20113142\n",
      "       239 -221527.32266996      +0.18737258\n",
      "       240 -221527.14935470      +0.17331526\n",
      "       241 -221526.98919325      +0.16016145\n",
      "       242 -221526.84062781      +0.14856544\n",
      "       243 -221526.70192263      +0.13870519\n",
      "       244 -221526.57150190      +0.13042073\n",
      "       245 -221526.44814153      +0.12336037\n",
      "       246 -221526.33103453      +0.11710699\n",
      "       247 -221526.21975987      +0.11127466\n",
      "       248 -221526.11418267      +0.10557721\n",
      "       249 -221526.01431181      +0.09987086\n",
      "       250 -221525.92014769      +0.09416412\n",
      "       251 -221525.83155993      +0.08858776\n",
      "       252 -221525.74822521      +0.08333472\n",
      "       253 -221525.66962766      +0.07859756\n",
      "       254 -221525.59509789      +0.07452977\n",
      "       255 -221525.52385889      +0.07123900\n",
      "       256 -221525.45505654      +0.06880235\n",
      "       257 -221525.38776901      +0.06728754\n",
      "       258 -221525.32100277      +0.06676623\n",
      "       259 -221525.25369544      +0.06730733\n",
      "       260 -221525.18475767      +0.06893777\n",
      "       261 -221525.11319510      +0.07156257\n",
      "       262 -221525.03833122      +0.07486388\n",
      "       263 -221524.96006373      +0.07826749\n",
      "       264 -221524.87894428      +0.08111945\n",
      "       265 -221524.79584973      +0.08309455\n",
      "       266 -221524.71131114      +0.08453859\n",
      "       267 -221524.62493184      +0.08637929\n",
      "       268 -221524.53520425      +0.08972760\n",
      "       269 -221524.43953097      +0.09567328\n",
      "       270 -221524.33403421      +0.10549675\n",
      "       271 -221524.21297478      +0.12105943\n",
      "       272 -221524.06794925      +0.14502553\n",
      "       273 -221523.88663811      +0.18131114\n",
      "       274 -221523.64676873      +0.23986939\n",
      "       275 -221523.28753354      +0.35923519\n",
      "       276 -221522.66682229      +0.62071125\n",
      "       277 -221521.85450164      +0.81232065\n",
      "       278 -221521.28907717      +0.56542447\n",
      "       279 -221520.94805216      +0.34102501\n",
      "       280 -221520.71002751      +0.23802465\n",
      "       281 -221520.52655090      +0.18347661\n",
      "       282 -221520.37638408      +0.15016682\n",
      "       283 -221520.24807657      +0.12830751\n",
      "       284 -221520.13445299      +0.11362358\n",
      "       285 -221520.03024210      +0.10421090\n",
      "       286 -221519.93053311      +0.09970898\n",
      "       287 -221519.82910539      +0.10142772\n",
      "       288 -221519.71590202      +0.11320336\n",
      "       289 -221519.57415809      +0.14174394\n",
      "       290 -221519.38583841      +0.18831968\n",
      "       291 -221519.16592564      +0.21991277\n",
      "       292 -221518.98172269      +0.18420295\n",
      "       293 -221518.86532317      +0.11639952\n",
      "       294 -221518.78880805      +0.07651513\n",
      "       295 -221518.72832810      +0.06047995\n",
      "       296 -221518.67512449      +0.05320360\n",
      "       297 -221518.62608297      +0.04904152\n",
      "       298 -221518.57966410      +0.04641887\n",
      "       299 -221518.53474653      +0.04491757\n",
      "       300 -221518.49017722      +0.04456931\n",
      "       301 -221518.44438443      +0.04579279\n",
      "       302 -221518.39472929      +0.04965514\n",
      "       303 -221518.33610857      +0.05862072\n",
      "       304 -221518.25770380      +0.07840477\n",
      "       305 -221518.13512211      +0.12258169\n",
      "       306 -221517.90930880      +0.22581332\n",
      "       307 -221517.41979089      +0.48951791\n",
      "       308 -221516.38446013      +1.03533076\n",
      "       309 -221515.37380311      +1.01065702\n",
      "       310 -221514.98912474      +0.38467836\n",
      "       311 -221514.79637614      +0.19274860\n",
      "       312 -221514.65552926      +0.14084688\n",
      "       313 -221514.53185397      +0.12367529\n",
      "       314 -221514.40310525      +0.12874872\n",
      "       315 -221514.22939028      +0.17371496\n",
      "       316 -221513.86045280      +0.36893748\n",
      "       317 -221512.76164008      +1.09881272\n",
      "       318 -221511.36709089      +1.39454920\n",
      "       319 -221510.67606216      +0.69102873\n",
      "       320 -221510.00608973      +0.66997243\n",
      "       321 -221509.30353513      +0.70255460\n",
      "       322 -221508.63211013      +0.67142500\n",
      "       323 -221507.99039038      +0.64171976\n",
      "       324 -221507.41315099      +0.57723939\n",
      "       325 -221506.95748977      +0.45566121\n",
      "       326 -221506.61647831      +0.34101147\n",
      "       327 -221506.34296605      +0.27351226\n",
      "       328 -221506.09986251      +0.24310354\n",
      "       329 -221505.86627795      +0.23358457\n",
      "       330 -221505.63186490      +0.23441305\n",
      "       331 -221505.39419275      +0.23767215\n",
      "       332 -221505.15656889      +0.23762385\n",
      "       333 -221504.92211715      +0.23445175\n",
      "       334 -221504.68718462      +0.23493253\n",
      "       335 -221504.44302792      +0.24415670\n",
      "       336 -221504.18894258      +0.25408534\n",
      "       337 -221503.94418941      +0.24475316\n",
      "       338 -221503.73487147      +0.20931794\n",
      "       339 -221503.56982737      +0.16504411\n",
      "       340 -221503.44192324      +0.12790413\n",
      "       341 -221503.34099759      +0.10092564\n",
      "       342 -221503.25918388      +0.08181371\n",
      "       343 -221503.19105868      +0.06812520\n",
      "       344 -221503.13285015      +0.05820853\n",
      "       345 -221503.08181638      +0.05103377\n",
      "       346 -221503.03585170      +0.04596468\n",
      "       347 -221502.99323681      +0.04261489\n",
      "       348 -221502.95246754      +0.04076927\n",
      "       349 -221502.91212295      +0.04034458\n",
      "       350 -221502.87074941      +0.04137355\n",
      "       351 -221502.82674668      +0.04400272\n",
      "       352 -221502.77825016      +0.04849653\n",
      "       353 -221502.72301315      +0.05523700\n",
      "       354 -221502.65831021      +0.06470295\n",
      "       355 -221502.58090686      +0.07740335\n",
      "       356 -221502.48717403      +0.09373282\n",
      "       357 -221502.37346617      +0.11370787\n",
      "       358 -221502.23694555      +0.13652062\n",
      "       359 -221502.07708590      +0.15985965\n",
      "       360 -221501.89776510      +0.17932080\n",
      "       361 -221501.70836118      +0.18940392\n",
      "       362 -221501.52032821      +0.18803298\n",
      "       363 -221501.33870810      +0.18162010\n",
      "       364 -221501.15671710      +0.18199100\n",
      "       365 -221500.96170593      +0.19501117\n",
      "       366 -221500.75229847      +0.20940747\n",
      "       367 -221500.55411779      +0.19818067\n",
      "       368 -221500.39971294      +0.15440485\n",
      "       369 -221500.29117933      +0.10853361\n",
      "       370 -221500.21090727      +0.08027206\n",
      "       371 -221500.14530051      +0.06560676\n",
      "       372 -221500.08781037      +0.05749014\n",
      "       373 -221500.03551031      +0.05230006\n",
      "       374 -221499.98697178      +0.04853854\n",
      "       375 -221499.94134674      +0.04562504\n",
      "       376 -221499.89792669      +0.04342005\n",
      "       377 -221499.85581362      +0.04211307\n",
      "       378 -221499.81347885      +0.04233477\n",
      "       379 -221499.76795190      +0.04552695\n",
      "       380 -221499.71325571      +0.05469619\n",
      "       381 -221499.63770863      +0.07554708\n",
      "       382 -221499.52082275      +0.11688589\n",
      "       383 -221499.33510736      +0.18571539\n",
      "       384 -221499.06443599      +0.27067137\n",
      "       385 -221498.73522725      +0.32920874\n",
      "       386 -221498.41254333      +0.32268392\n",
      "       387 -221498.14682327      +0.26572006\n",
      "       388 -221497.94454840      +0.20227486\n",
      "       389 -221497.78527402      +0.15927438\n",
      "       390 -221497.64368145      +0.14159258\n",
      "       391 -221497.49936821      +0.14431324\n",
      "       392 -221497.34160727      +0.15776094\n",
      "       393 -221497.17434678      +0.16726049\n",
      "       394 -221497.01368040      +0.16066638\n",
      "       395 -221496.87353884      +0.14014155\n",
      "       396 -221496.75715114      +0.11638770\n",
      "       397 -221496.66124151      +0.09590963\n",
      "       398 -221496.58128032      +0.07996120\n",
      "       399 -221496.51329053      +0.06798978\n",
      "       400 -221496.45402258      +0.05926795\n",
      "       401 -221496.40076771      +0.05325487\n",
      "       402 -221496.35114734      +0.04962038\n",
      "       403 -221496.30294946      +0.04819787\n",
      "       404 -221496.25406168      +0.04888778\n",
      "       405 -221496.20259791      +0.05146377\n",
      "       406 -221496.14735681      +0.05524111\n",
      "       407 -221496.08861951      +0.05873730\n",
      "       408 -221496.02879390      +0.05982561\n",
      "       409 -221495.97191686      +0.05687704\n",
      "       410 -221495.92177171      +0.05014515\n",
      "       411 -221495.88014204      +0.04162967\n",
      "       412 -221495.84668932      +0.03345272\n",
      "       413 -221495.81997665      +0.02671266\n",
      "       414 -221495.79841081      +0.02156585\n",
      "       415 -221495.78066024      +0.01775056\n",
      "       416 -221495.76572295      +0.01493729\n",
      "       417 -221495.75286917      +0.01285378\n",
      "       418 -221495.74156796      +0.01130121\n",
      "       419 -221495.73142895      +0.01013901\n",
      "       420 -221495.72216178      +0.00926717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [RUN 1/15] logL = -221495.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -254021.61436221             +nan\n",
      "         2 -243594.02459014  +10427.58977207\n",
      "         3 -238911.65136839   +4682.37322175\n",
      "         4 -235753.54347905   +3158.10788934\n",
      "         5 -233799.70604685   +1953.83743220\n",
      "         6 -232593.77978567   +1205.92626118\n",
      "         7 -231777.74634063    +816.03344504\n",
      "         8 -231042.44561464    +735.30072599\n",
      "         9 -230221.94800631    +820.49760833\n",
      "        10 -229441.71615256    +780.23185375\n",
      "        11 -228751.00944854    +690.70670401\n",
      "        12 -228120.80311608    +630.20633247\n",
      "        13 -227630.15057449    +490.65254159\n",
      "        14 -227313.19749876    +316.95307573\n",
      "        15 -227131.63218734    +181.56531142\n",
      "        16 -227009.28183505    +122.35035229\n",
      "        17 -226904.24139988    +105.04043517\n",
      "        18 -226797.42294580    +106.81845409\n",
      "        19 -226669.68365552    +127.73929028\n",
      "        20 -226520.70270411    +148.98095141\n",
      "        21 -226349.13250522    +171.57019888\n",
      "        22 -226180.49183031    +168.64067492\n",
      "        23 -226020.79270127    +159.69912904\n",
      "        24 -225869.05252042    +151.74018085\n",
      "        25 -225735.16672352    +133.88579690\n",
      "        26 -225620.48121324    +114.68551028\n",
      "        27 -225522.09502283     +98.38619041\n",
      "        28 -225425.93958260     +96.15544023\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 186\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved HMMlearn permutation results to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPKL_OUT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 150\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m STATE_COUNTS:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting HMM for k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 150\u001b[0m     model, logL, fo, paths \u001b[38;5;241m=\u001b[39m \u001b[43mfit_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_REPEATS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  [WARN] No model converged for k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 72\u001b[0m, in \u001b[0;36mfit_best_model\u001b[0;34m(X, lengths, k, n_repeats)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_repeats \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m         model, logL, paths \u001b[38;5;241m=\u001b[39m \u001b[43mfit_hmm_prestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m         all_models\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     74\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogL\u001b[39m\u001b[38;5;124m\"\u001b[39m: logL,\n\u001b[1;32m     76\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39mmeans_,\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaths\u001b[39m\u001b[38;5;124m\"\u001b[39m: paths\n\u001b[1;32m     78\u001b[0m         })\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  [RUN \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_repeats\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] logL = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogL\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 54\u001b[0m, in \u001b[0;36mfit_hmm_prestore\u001b[0;34m(X, lengths, k, max_iter)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_hmm_prestore\u001b[39m(X, lengths, k, max_iter\u001b[38;5;241m=\u001b[39mMAX_ITER):\n\u001b[1;32m     53\u001b[0m     model \u001b[38;5;241m=\u001b[39m hmm\u001b[38;5;241m.\u001b[39mGaussianHMM(n_components\u001b[38;5;241m=\u001b[39mk, covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39mmax_iter, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     logL \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(X, lengths)\n\u001b[1;32m     56\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X, lengths)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/hmmlearn/base.py:485\u001b[0m, in \u001b[0;36m_AbstractHMM.fit\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor_\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter):\n\u001b[0;32m--> 485\u001b[0m     stats, curr_logprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_estep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;66;03m# Compute lower bound before updating model parameters\u001b[39;00m\n\u001b[1;32m    488\u001b[0m     lower_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_lower_bound(curr_logprob)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/hmmlearn/base.py:764\u001b[0m, in \u001b[0;36m_AbstractHMM._do_estep\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    762\u001b[0m curr_logprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_X \u001b[38;5;129;01min\u001b[39;00m _utils\u001b[38;5;241m.\u001b[39msplit_X_lengths(X, lengths):\n\u001b[0;32m--> 764\u001b[0m     lattice, logprob, posteriors, fwdlattice, bwdlattice \u001b[38;5;241m=\u001b[39m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;66;03m# Derived HMM classes will implement the following method to\u001b[39;00m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# update their probability distributions, so keep\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;66;03m# a single call to this method for simplicity.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulate_sufficient_statistics(\n\u001b[1;32m    769\u001b[0m         stats, sub_X, lattice, posteriors, fwdlattice,\n\u001b[1;32m    770\u001b[0m         bwdlattice)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/hmmlearn/base.py:883\u001b[0m, in \u001b[0;36mBaseHMM._fit_log\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_fit_log\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m--> 883\u001b[0m     log_frameprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m     log_prob, fwdlattice \u001b[38;5;241m=\u001b[39m _hmmc\u001b[38;5;241m.\u001b[39mforward_log(\n\u001b[1;32m    885\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartprob_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_, log_frameprob)\n\u001b[1;32m    886\u001b[0m     bwdlattice \u001b[38;5;241m=\u001b[39m _hmmc\u001b[38;5;241m.\u001b[39mbackward_log(\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartprob_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_, log_frameprob)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/hmmlearn/_emissions.py:130\u001b[0m, in \u001b[0;36mBaseGaussianHMM._compute_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_compute_log_likelihood\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_multivariate_normal_density\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeans_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_covars_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariance_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/hmmlearn/stats.py:42\u001b[0m, in \u001b[0;36mlog_multivariate_normal_density\u001b[0;34m(X, means, covars, covariance_type)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mCompute the log probability under a multivariate Gaussian distribution.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    X under each of the n_components multivariate Gaussian distributions.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m log_multivariate_normal_density_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspherical\u001b[39m\u001b[38;5;124m'\u001b[39m: _log_multivariate_normal_density_spherical,\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtied\u001b[39m\u001b[38;5;124m'\u001b[39m: _log_multivariate_normal_density_tied,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiag\u001b[39m\u001b[38;5;124m'\u001b[39m: _log_multivariate_normal_density_diag,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m: _log_multivariate_normal_density_full}\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_multivariate_normal_density_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcovariance_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovars\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/hmmlearn/stats.py:93\u001b[0m, in \u001b[0;36m_log_multivariate_normal_density_full\u001b[0;34m(X, means, covars, min_covar)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcovars\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be symmetric, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive-definite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m     cv_log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39mdiagonal(cv_chol)))\n\u001b[0;32m---> 93\u001b[0m     cv_sol \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_triangular\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv_chol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     94\u001b[0m     log_prob\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m.5\u001b[39m \u001b[38;5;241m*\u001b[39m (nf \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi)\n\u001b[1;32m     95\u001b[0m                            \u001b[38;5;241m+\u001b[39m (cv_sol \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     96\u001b[0m                            \u001b[38;5;241m+\u001b[39m cv_log_det))\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtranspose(log_prob)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/_lib/_util.py:1226\u001b[0m, in \u001b[0;36m_apply_over_batch.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;66;03m# Early exit if call is not batched\u001b[39;00m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(batch_shapes):\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;66;03m# Determine broadcasted batch shape\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbroadcast_shapes(\u001b[38;5;241m*\u001b[39mbatch_shapes)  \u001b[38;5;66;03m# Gives OK error message\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/linalg/_basic.py:507\u001b[0m, in \u001b[0;36msolve_triangular\u001b[0;34m(a, b, trans, lower, unit_diagonal, overwrite_b, check_finite)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mempty_like(b1, dtype\u001b[38;5;241m=\u001b[39mdt_nonempty)\n\u001b[1;32m    505\u001b[0m overwrite_b \u001b[38;5;241m=\u001b[39m overwrite_b \u001b[38;5;129;01mor\u001b[39;00m _datacopied(b1, b)\n\u001b[0;32m--> 507\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_solve_triangular\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit_diagonal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/scipy/linalg/_basic.py:518\u001b[0m, in \u001b[0;36m_solve_triangular\u001b[0;34m(a1, b1, trans, lower, unit_diagonal, overwrite_b)\u001b[0m\n\u001b[1;32m    516\u001b[0m trtrs, \u001b[38;5;241m=\u001b[39m get_lapack_funcs((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrtrs\u001b[39m\u001b[38;5;124m'\u001b[39m,), (a1, b1))\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a1\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous \u001b[38;5;129;01mor\u001b[39;00m trans \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 518\u001b[0m     x, info \u001b[38;5;241m=\u001b[39m \u001b[43mtrtrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtrans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munitdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit_diagonal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;66;03m# transposed system is solved since trtrs expects Fortran ordering\u001b[39;00m\n\u001b[1;32m    522\u001b[0m     x, info \u001b[38;5;241m=\u001b[39m trtrs(a1\u001b[38;5;241m.\u001b[39mT, b1, overwrite_b\u001b[38;5;241m=\u001b[39moverwrite_b, lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m lower,\n\u001b[1;32m    523\u001b[0m                     trans\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m trans, unitdiag\u001b[38;5;241m=\u001b[39munit_diagonal)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === Settings ===\n",
    "INPUT_DIR       = \"/home/jovyan/narratives-project/shirer_components\"\n",
    "DATASET         = \"timeseries\"\n",
    "STATE_COUNTS    = [10]\n",
    "N_REPEATS       = 15\n",
    "N_PERMUTATIONS  = 100\n",
    "MAX_ITER        = 500\n",
    "N_JOBS          = 4    # use all cores\n",
    "PKL_OUT         = \"/home/jovyan/narratives-project/hmm-objects/hmmlearn_consensus_results_k10perm.pkl\"\n",
    "RUN_PERMUTATIONS = True  # set to False to skip permutations\n",
    "\n",
    "def load_data(input_dir):\n",
    "    data = []\n",
    "    for path in sorted(glob.glob(os.path.join(input_dir, \"*.h5\"))):\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            ts = f[DATASET][()].T\n",
    "        ts = StandardScaler().fit_transform(ts)\n",
    "        data.append(ts)\n",
    "    return data\n",
    "\n",
    "def compute_num_parameters(n_states, n_features):\n",
    "    \"\"\"\n",
    "    Cacl\n",
    "    \"\"\"\n",
    "    p_init  = n_states - 1\n",
    "    p_trans = n_states * (n_states - 1)\n",
    "    p_means = n_states * n_features\n",
    "    p_cov   = n_states * (n_features * (n_features + 1) // 2)\n",
    "    return p_init + p_trans + p_means + p_cov\n",
    "\n",
    "def fractional_occupancy(state_seqs, k):\n",
    "    \"\"\"\n",
    "    For each state sequence (from each subject), counts how often each state\n",
    "    was active and averages across all timepoints to get fraction of time each \n",
    "    state was active. Used to check for unused states.\n",
    "    \"\"\"\n",
    "    fo = np.zeros(k)\n",
    "    total_len = 0\n",
    "    for seq in state_seqs:\n",
    "        fo += np.bincount(seq, minlength=k)\n",
    "        total_len += len(seq)\n",
    "    return fo / total_len\n",
    "\n",
    "def circular_shift(ts):\n",
    "    \"\"\"\n",
    "    Rolls a time series forward by a random number of TRs. Used \n",
    "    to generate null data for the permutation testing.\n",
    "    \"\"\"\n",
    "    shift = np.random.randint(1, ts.shape[0])\n",
    "    return np.roll(ts, shift, axis=0)\n",
    "\n",
    "def fit_hmm_prestore(X, lengths, k, max_iter=MAX_ITER):\n",
    "    model = hmm.GaussianHMM(n_components=k, covariance_type='full', n_iter=max_iter, verbose=True)\n",
    "    model.fit(X, lengths)\n",
    "    logL = model.score(X, lengths)\n",
    "    hidden = model.predict(X, lengths)\n",
    "    # split hidden back into per-subject paths\n",
    "    paths, offset = [], 0\n",
    "    for L in lengths:\n",
    "        paths.append(hidden[offset:offset + L])\n",
    "        offset += L\n",
    "    return model, logL, paths\n",
    "\n",
    "def fit_best_model(X, lengths, k, n_repeats):\n",
    "    \"\"\"\n",
    "    Run N HMM repetitions, select most representative model by state alignment (Hungarian method).\n",
    "    \"\"\"\n",
    "    all_models = []\n",
    "\n",
    "    for run in range(1, n_repeats + 1):\n",
    "        try:\n",
    "            model, logL, paths = fit_hmm_prestore(X, lengths, k)\n",
    "            all_models.append({\n",
    "                \"model\": model,\n",
    "                \"logL\": logL,\n",
    "                \"means\": model.means_,\n",
    "                \"paths\": paths\n",
    "            })\n",
    "            print(f\"  [RUN {run}/{n_repeats}] logL = {logL:.1f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  [ERROR] run {run} k={k}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not all_models:\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Align all mean matrices and compute similarity\n",
    "    means_all = [m[\"means\"] for m in all_models]\n",
    "    scores = align_and_score(means_all)\n",
    "    best_idx = np.argmax(scores)\n",
    "    best = all_models[best_idx]\n",
    "\n",
    "    fo = fractional_occupancy(best[\"paths\"], k)\n",
    "    print(f\"  [BEST] run={best_idx+1}/{n_repeats} k={k} logL={best['logL']:.1f}, FO min={fo.min():.3f}\")\n",
    "    return best[\"model\"], best[\"logL\"], fo, best[\"paths\"]\n",
    "\n",
    "def run_permutations(X, lengths, data, k, logL_real):\n",
    "    def one_perm(_):\n",
    "        shifted = [circular_shift(ts) for ts in data]\n",
    "        Xs = np.vstack(shifted)\n",
    "        try:\n",
    "            _, logL, _ = fit_hmm_prestore(Xs, lengths, k)\n",
    "            return logL\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    nulls = Parallel(n_jobs=N_JOBS)(\n",
    "        delayed(one_perm)(i) for i in range(N_PERMUTATIONS)\n",
    "    )\n",
    "    null_logLs = [nl for nl in nulls if nl is not None]\n",
    "    pval = np.mean([logL_real <= nl for nl in null_logLs])\n",
    "    return null_logLs, pval\n",
    "\n",
    "def align_and_score(all_means):\n",
    "    n_runs = len(all_means)\n",
    "    scores = np.zeros(n_runs)\n",
    "\n",
    "    for i in range(n_runs):\n",
    "        curr = all_means[i]\n",
    "        sims = []\n",
    "        for j in range(n_runs):\n",
    "            if i == j:\n",
    "                continue\n",
    "            other = all_means[j]\n",
    "            # cost matrix = negative correlation\n",
    "            cost = np.zeros((curr.shape[0], other.shape[0]))\n",
    "            for s1 in range(curr.shape[0]):\n",
    "                for s2 in range(other.shape[0]):\n",
    "                    r, _ = pearsonr(curr[s1], other[s2])\n",
    "                    cost[s1, s2] = -r  # negative for minimization\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "            aligned_corrs = [-cost[r, c] for r, c in zip(row_ind, col_ind)]\n",
    "            sims.append(np.mean(aligned_corrs))\n",
    "        scores[i] = np.mean(sims)\n",
    "    return scores\n",
    "\n",
    "def main():\n",
    "    data = load_data(INPUT_DIR)\n",
    "    # pre-stack once\n",
    "    X       = np.vstack(data)\n",
    "    lengths = [d.shape[0] for d in data]\n",
    "\n",
    "    print(f\"[DEBUG] Loaded {len(data)} subjects\")\n",
    "    for i, d in enumerate(data):\n",
    "        print(f\"  Subject {i}: shape={d.shape}, mean={np.mean(d):.4f}, std={np.std(d):.4f}\")\n",
    "\n",
    "    results = []\n",
    "    for k in STATE_COUNTS:\n",
    "        print(f\"Fitting HMM for k={k}...\")\n",
    "        model, logL, fo, paths = fit_best_model(X, lengths, k, N_REPEATS)\n",
    "        if model is None:\n",
    "            print(f\"  [WARN] No model converged for k={k}\")\n",
    "            continue\n",
    "\n",
    "        # model selection metrics\n",
    "        n_params = compute_num_parameters(k, data[0].shape[1])\n",
    "        aic = 2 * n_params - 2 * logL\n",
    "        bic = np.log(sum(lengths)) * n_params - 2 * logL\n",
    "        print(f\"  Done. logL={logL:.1f}, AIC={aic:.1f}, FO min={fo.min():.3f}\")\n",
    "\n",
    "        null_logLs, pval = [], None\n",
    "        if RUN_PERMUTATIONS:\n",
    "            print(f\"  Running {N_PERMUTATIONS} permutations for k={k}...\")\n",
    "            null_logLs, pval = run_permutations(X, lengths, data, k, logL)\n",
    "            print(f\"  Null model p-value: {pval:.4f}\")\n",
    "        else:\n",
    "            print(f\"  [SKIP] Permutations skipped for k={k}\")\n",
    "\n",
    "        results.append({\n",
    "            \"k\": k,\n",
    "            \"model\": model,\n",
    "            \"logL\": logL,\n",
    "            \"AIC\": aic,\n",
    "            \"BIC\": bic,\n",
    "            \"FO\": fo,\n",
    "            \"subject_paths\": paths,\n",
    "            \"null_logLs\": null_logLs,\n",
    "            \"pval\": pval\n",
    "        })\n",
    "\n",
    "    with open(PKL_OUT, \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(f\"Saved HMMlearn permutation results to {PKL_OUT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acbceb6-679f-479d-a48b-85b2048fbf51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
