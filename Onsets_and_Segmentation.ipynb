{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081921dc-88bf-4815-8688-d9bc263cd200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ce7094-50b8-4c0e-81c1-7dd4e5903c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "all_iter = []\n",
    "for i in range(6):\n",
    "    file_path = f'../GPT_event_share/Pieman/outputs/Pieman_iter_{i}_version__Events.pkl'\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        all_iter.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bfb3b0f-a04f-4ea5-8f53-a72ec2b9acf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"And one day I'm walking toward the campus center. And out comes the elusive Dean McGowan, architect of a policy to replace Fordham's traditionally working to middle class students with wealthier, more prestigious ones. So I whip out my notebook. And I go up to him and I say: Dean McGowan, is it true that Fordham University plans to raise tuition substantially above the inflation rate? And if so, wouldn't that be a betrayal of its mission?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_iter[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89abdfe-c2e2-4265-9360-b066d27f1d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0       1          2          3\n",
      "0            I       i  15.089999  15.169999\n",
      "1        began   began  15.170000  15.510000\n",
      "2           my      my  15.509999  15.699999\n",
      "3  illustrious   <unk>  15.710000  16.310000\n",
      "4       career  career  16.330000  16.940000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "align_df = pd.read_csv('../gentle/pieman/align.csv', header=None)\n",
    "\n",
    "print(align_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95576e83-9b7a-4c77-a307-2c8f9badbdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TR  Time_seconds\n",
      "0      1           0.0\n",
      "1      2           1.5\n",
      "2      3           3.0\n",
      "3      4           4.5\n",
      "4      5           6.0\n",
      "..   ...           ...\n",
      "277  278         415.5\n",
      "278  279         417.0\n",
      "279  280         418.5\n",
      "280  281         420.0\n",
      "281  282         421.5\n",
      "\n",
      "[282 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "n_trs = 282\n",
    "tr_length = 1.5\n",
    "\n",
    "# Create DataFrame\n",
    "trs_df = pd.DataFrame({\n",
    "    'TR': range(1, 1+n_trs),\n",
    "    'Time_seconds': [tr * tr_length for tr in range(n_trs)]\n",
    "})\n",
    "\n",
    "print(trs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fccfb509-50bd-4c45-9e39-dba2ac389581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity\n",
    "align_df.columns = ['word_raw', 'word_clean', 'start', 'end']\n",
    "\n",
    "align_df = align_df.dropna()\n",
    "\n",
    "# Set the lag in seconds (e.g., 4.5s)\n",
    "hemodynamic_lag = 4.5\n",
    "\n",
    "# Create a new column for adjusted start time\n",
    "align_df['start_lagged'] = align_df['start'] + hemodynamic_lag\n",
    "\n",
    "# Sort both DataFrames by time\n",
    "align_df_sorted = align_df.sort_values('start_lagged')\n",
    "trs_df_sorted = trs_df.sort_values('Time_seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11d2d231-9eb2-4cc3-a57a-3a4172071644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word_raw word_clean      start        end  start_lagged  TR\n",
      "0            I          i  15.089999  15.169999     19.589999  14\n",
      "1        began      began  15.170000  15.510000     19.670000  14\n",
      "2           my         my  15.509999  15.699999     20.009999  14\n",
      "3  illustrious      <unk>  15.710000  16.310000     20.210000  14\n",
      "4       career     career  16.330000  16.940000     20.830000  14\n"
     ]
    }
   ],
   "source": [
    "# Assign TRs using the lag-adjusted start time\n",
    "word_with_tr = pd.merge_asof(\n",
    "    align_df_sorted,\n",
    "    trs_df_sorted,\n",
    "    left_on='start_lagged',\n",
    "    right_on='Time_seconds',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "# Clean up columns: drop raw TR time if not needed\n",
    "word_with_tr = word_with_tr.drop(columns='Time_seconds')\n",
    "\n",
    "# View result\n",
    "print(word_with_tr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c1411b2-731b-4b86-b7d4-41f4cfceed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_indices = [420, 498, 880]\n",
    "\n",
    "# Loop through all 6 segmentation variants\n",
    "for seg_version in range(6):\n",
    "    segment_ids = []\n",
    "    flat_tokens = []\n",
    "\n",
    "    for idx, segment in enumerate(all_iter[seg_version]):\n",
    "        words = segment.split()\n",
    "        flat_tokens.extend(words)\n",
    "        segment_ids.extend([idx] * len(words))\n",
    "\n",
    "    # Drop the same bad tokens\n",
    "    flat_tokens_cleaned = [tok for i, tok in enumerate(flat_tokens) if i not in dropped_indices]\n",
    "    segment_ids_cleaned = [sid for i, sid in enumerate(segment_ids) if i not in dropped_indices]\n",
    "\n",
    "    # Add to main dataframe\n",
    "    colname = f'segment_idx_{seg_version}'\n",
    "    word_with_tr[colname] = segment_ids_cleaned[:len(word_with_tr)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8102e210-d2cf-4143-b7a4-2b5a448743fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE TR IS THE LAGGED TR\n",
    "word_with_tr.to_csv(\"pieman_segments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dcc790-c55a-4ef8-8624-1039d83b9d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5585c-679f-48f2-8c50-749329960595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
