{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5927b3-365a-411b-8cc2-98f8b843b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load pieman_segments\n",
    "pieman_segments = pd.read_csv(\"pieman_segments.csv\")\n",
    "\n",
    "# Compute row-wise mode of LLM segment indices\n",
    "segment_cols = [f\"segment_idx_{i}\" for i in range(6)]\n",
    "pieman_segments[\"mode_segment\"] = pieman_segments[segment_cols].apply(lambda row: row.mode().iloc[0], axis=1)\n",
    "\n",
    "# Keep only TR and mode_segment\n",
    "clean_seg = pieman_segments[[\"TR\", \"mode_segment\"]].copy()\n",
    "\n",
    "# Get one row per TR (e.g., first token in TR)\n",
    "clean_seg = clean_seg.groupby(\"TR\").agg({\"mode_segment\": \"first\"}).reset_index()\n",
    "\n",
    "# Compute segment boundary (no boundary on the first row)\n",
    "clean_seg[\"segment_boundary\"] = (clean_seg[\"mode_segment\"] != clean_seg[\"mode_segment\"].shift()).astype(int)\n",
    "clean_seg.loc[0, \"segment_boundary\"] = 0  # make sure first row is 0\n",
    "\n",
    "# Create full TR range\n",
    "full_trs = pd.DataFrame({\"TR\": range(1, 301)})\n",
    "\n",
    "# Merge with existing data\n",
    "clean_seg_full = pd.merge(full_trs, clean_seg, on=\"TR\", how=\"left\")\n",
    "\n",
    "# Fill missing segment_boundary with 0\n",
    "clean_seg_full[\"segment_boundary\"] = clean_seg_full[\"segment_boundary\"].fillna(0).astype(int)\n",
    "\n",
    "# Have ready to feed into cross correlation\n",
    "event_boundaries = list(clean_seg_full[\"segment_boundary\"])\n",
    "\n",
    "# Start with segment_boundary as a float list to allow NaNs\n",
    "event_boundaries = clean_seg_full[\"segment_boundary\"].astype(float).tolist()\n",
    "\n",
    "# Set first 13 elements to NaN\n",
    "event_boundaries[:13] = np.nan\n",
    "\n",
    "# Set from index 292 to the end to NaN\n",
    "event_boundaries[292:] = np.nan\n",
    "\n",
    "# Remove all NaN values\n",
    "event_boundaries = event_boundaries[~np.isnan(event_boundaries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53801f08-8cb8-4af0-91f4-e9ec4d13ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_transitions(state_vector):\n",
    "    transitions = np.zeros_like(state_vector)\n",
    "    transitions[1:] = state_vector[1:] != state_vector[:-1]\n",
    "    return transitions.astype(int)\n",
    "\n",
    "subject_list = [\n",
    "    \"sub-002\", \"sub-003\", \"sub-004\", \"sub-005\", \"sub-006\", \"sub-007\", \"sub-008\",\n",
    "    \"sub-009\", \"sub-010\", \"sub-011\", \"sub-012\", \"sub-013\", \"sub-014\", \"sub-015\",\n",
    "    \"sub-016\", \"sub-017\", \"sub-018\", \"sub-019\", \"sub-020\", \"sub-023\", \"sub-024\",\n",
    "    \"sub-025\", \"sub-026\", \"sub-027\", \"sub-028\", \"sub-029\", \"sub-030\", \"sub-031\",\n",
    "    \"sub-032\", \"sub-033\", \"sub-034\", \"sub-035\", \"sub-036\", \"sub-037\", \"sub-039\",\n",
    "    \"sub-040\", \"sub-041\", \"sub-042\", \"sub-043\", \"sub-044\", \"sub-045\", \"sub-046\",\n",
    "    \"sub-047\", \"sub-048\", \"sub-049\", \"sub-050\", \"sub-051\", \"sub-052\", \"sub-053\",\n",
    "    \"sub-054\", \"sub-055\", \"sub-057\", \"sub-058\", \"sub-059\", \"sub-060\", \"sub-061\",\n",
    "    \"sub-062\", \"sub-063\", \"sub-064\", \"sub-065\", \"sub-066\", \"sub-067\", \"sub-070\",\n",
    "    \"sub-071\", \"sub-072\", \"sub-073\", \"sub-074\", \"sub-075\", \"sub-076\", \"sub-077\",\n",
    "    \"sub-078\", \"sub-079\", \"sub-080\", \"sub-081\", \"sub-082\"\n",
    "]\n",
    "\n",
    "# Import HMM results\n",
    "# Read in the CSV\n",
    "df = pd.read_csv(\"viterbi-paths/statepaths_k10.csv\")\n",
    "# Initialize list to hold state vectors\n",
    "state_vectors = []\n",
    "# Loop through each subject (assuming each row is a subject and columns are timepoints named 0 to 279)\n",
    "for i in range(len(subject_list)):\n",
    "    # Grab the state time series as a list (convert from row to list of ints)\n",
    "    state_series = df.loc[i, '0':'278'].astype(int).tolist()\n",
    "    state_vectors.append(state_series)\n",
    "\n",
    "transitions_list = []\n",
    "# Apply get_state_transitions to HMM results for each subject\n",
    "for i in range(len(subject_list)):\n",
    "    transitions = get_state_transitions(state_vectors)\n",
    "    transitions_list.append(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d87812b-beab-421f-bf9f-389a6851f4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_vectors[1])\n",
    "len(event_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99c8468-edb0-47db-b33c-110129d2d787",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m event_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(event_boundaries)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# True correlation\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m lags, true_corr \u001b[38;5;241m=\u001b[39m \u001b[43mcross_correlation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransition_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_lag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Null distribution via circular shift\u001b[39;00m\n\u001b[1;32m     32\u001b[0m null_corrs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_permutations, \u001b[38;5;28mlen\u001b[39m(true_corr)))\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mcross_correlation\u001b[0;34m(a, b, max_lag)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcross_correlation\u001b[39m(a, b, max_lag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(b)\n\u001b[1;32m      5\u001b[0m     a \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(a)\n\u001b[1;32m      6\u001b[0m     b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(b)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.signal import correlate\n",
    "\n",
    "def cross_correlation(a, b, max_lag=10):\n",
    "    assert len(a) == len(b)\n",
    "    a = a - np.mean(a)\n",
    "    b = b - np.mean(b)\n",
    "    corr = correlate(a, b, mode='full')\n",
    "    lags = np.arange(-len(a) + 1, len(a))\n",
    "    center = len(a) - 1\n",
    "    lag_range = range(center - max_lag, center + max_lag + 1)\n",
    "    return lags[lag_range], corr[lag_range]\n",
    "\n",
    "# Parameters\n",
    "n_permutations = 500\n",
    "max_lag = 10\n",
    "\n",
    "results = {\n",
    "    \"Lags\": [],\n",
    "    \"Correlations\": [],\n",
    "    \"P_Values\": []\n",
    "}\n",
    "\n",
    "for i in range(len(subject_list)):\n",
    "    transition_vector = transitions_list[i]\n",
    "    transition_vector = np.array(transition_vector)\n",
    "    event_vector = np.array(event_boundaries)\n",
    "\n",
    "    # True correlation\n",
    "    lags, true_corr = cross_correlation(transition_vector, event_vector, max_lag=max_lag)\n",
    "\n",
    "    # Null distribution via circular shift\n",
    "    null_corrs = np.zeros((n_permutations, len(true_corr)))\n",
    "\n",
    "    for p in range(n_permutations):\n",
    "        shift_amount = np.random.randint(1, len(event_vector))  # exclude 0 shift\n",
    "        shifted = np.roll(event_vector, shift_amount)\n",
    "        _, permuted_corr = cross_correlation(transition_vector, shifted, max_lag=max_lag)\n",
    "        null_corrs[p] = permuted_corr\n",
    "\n",
    "    # Compute two-tailed p-values\n",
    "    p_vals = np.mean(np.abs(null_corrs) >= np.abs(true_corr), axis=0)\n",
    "\n",
    "    # Store results\n",
    "    results[\"Lags\"].append(lags)\n",
    "    results[\"Correlations\"].append(true_corr)\n",
    "    results[\"P_Values\"].append(p_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4422ef-2137-45cf-8d98-e2f26f3e7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Flatten all p-values to correct across all subjects Ã— lags\n",
    "all_pvals = np.concatenate(results[\"P_Values\"])\n",
    "_, pvals_fdr, _, _ = multipletests(all_pvals, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "# Store FDR-corrected p-values back into results\n",
    "fdr_corrected = np.split(pvals_fdr, len(subject_list))\n",
    "results[\"P_Values_FDR\"] = fdr_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26d7a9-78db-415e-8277-a8167fea7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_results = []\n",
    "for subj, (lags, corrs, raw_p, fdr_p) in enumerate(zip(\n",
    "        results[\"Lags\"], results[\"Correlations\"], results[\"P_Values\"], results[\"P_Values_FDR\"])):\n",
    "    for lag, corr, p, pfdr in zip(lags, corrs, raw_p, fdr_p):\n",
    "        flat_results.append({\n",
    "            \"Subject\": subj + 1,\n",
    "            \"Lag\": lag,\n",
    "            \"Correlation\": corr,\n",
    "            \"P_Value\": p,\n",
    "            \"P_Value_FDR\": pfdr\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(flat_results)\n",
    "\n",
    "# Add significance flag for coloring\n",
    "df[\"Significant\"] = df[\"P_Value_FDR\"] < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c83d4f-cb2d-4f54-ac28-00499385f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot with x jitter and exact y-values\n",
    "sns.stripplot(\n",
    "    data=df,\n",
    "    x=\"Lag\",\n",
    "    y=\"Correlation\",\n",
    "    hue=\"Significant\",\n",
    "    palette={True: \"green\", False: \"red\"},\n",
    "    dodge=False,\n",
    "    jitter=0.2,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.title(\"Cross-Correlation Across Lags with FDR-Corrected Significance\")\n",
    "plt.xlabel(\"Lag\")\n",
    "plt.ylabel(\"Cross-Correlation\")\n",
    "plt.legend(title=\"FDR Significant\", loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
