{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5927b3-365a-411b-8cc2-98f8b843b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load pieman_segments\n",
    "pieman_segments = pd.read_csv(\"pieman_segments.csv\")\n",
    "\n",
    "# Compute row-wise mode of LLM segment indices\n",
    "segment_cols = [f\"segment_idx_{i}\" for i in range(6)]\n",
    "pieman_segments[\"mode_segment\"] = pieman_segments[segment_cols].apply(lambda row: row.mode().iloc[0], axis=1)\n",
    "\n",
    "# Keep only TR and mode_segment\n",
    "clean_seg = pieman_segments[[\"TR\", \"mode_segment\"]].copy()\n",
    "\n",
    "# Get one row per TR (e.g., first token in TR)\n",
    "clean_seg = clean_seg.groupby(\"TR\").agg({\"mode_segment\": \"first\"}).reset_index()\n",
    "\n",
    "# Compute segment boundary (no boundary on the first row)\n",
    "clean_seg[\"segment_boundary\"] = (clean_seg[\"mode_segment\"] != clean_seg[\"mode_segment\"].shift()).astype(int)\n",
    "clean_seg.loc[0, \"segment_boundary\"] = 0  # make sure first row is 0\n",
    "\n",
    "# Have ready to feed into cross correlation\n",
    "event_boundaries = clean_seg[\"segment_boundary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53801f08-8cb8-4af0-91f4-e9ec4d13ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_state_transitions(state_vector):\n",
    "    transitions = np.zeros_like(state_vector)\n",
    "    transitions[1:] = state_vector[1:] != state_vector[:-1]\n",
    "    return transitions.astype(int)\n",
    "\n",
    "subject_list = [\n",
    "    \"sub-002\", \"sub-003\", \"sub-004\", \"sub-005\", \"sub-006\", \"sub-007\", \"sub-008\",\n",
    "    \"sub-009\", \"sub-010\", \"sub-011\", \"sub-012\", \"sub-013\", \"sub-014\", \"sub-015\",\n",
    "    \"sub-016\", \"sub-017\", \"sub-018\", \"sub-019\", \"sub-020\", \"sub-023\", \"sub-024\",\n",
    "    \"sub-025\", \"sub-026\", \"sub-027\", \"sub-028\", \"sub-029\", \"sub-030\", \"sub-031\",\n",
    "    \"sub-032\", \"sub-033\", \"sub-034\", \"sub-035\", \"sub-036\", \"sub-037\", \"sub-039\",\n",
    "    \"sub-040\", \"sub-041\", \"sub-042\", \"sub-043\", \"sub-044\", \"sub-045\", \"sub-046\",\n",
    "    \"sub-047\", \"sub-048\", \"sub-049\", \"sub-050\", \"sub-051\", \"sub-052\", \"sub-053\",\n",
    "    \"sub-054\", \"sub-055\", \"sub-057\", \"sub-058\", \"sub-059\", \"sub-060\", \"sub-061\",\n",
    "    \"sub-062\", \"sub-063\", \"sub-064\", \"sub-065\", \"sub-066\", \"sub-067\", \"sub-070\",\n",
    "    \"sub-071\", \"sub-072\", \"sub-073\", \"sub-074\", \"sub-075\", \"sub-076\", \"sub-077\",\n",
    "    \"sub-078\", \"sub-079\", \"sub-080\", \"sub-081\", \"sub-082\"\n",
    "]\n",
    "\n",
    "# Import HMM results\n",
    "state_vectors = []\n",
    "for i in subject_list:\n",
    "    #state_vectors.append()\n",
    "\n",
    "transitions_list = []\n",
    "# Apply get_state_transitions to HMM results for each subject\n",
    "for i in len(subject_list):\n",
    "    transitions = get_state_transitions(state_vectors)\n",
    "    transitions_list.append(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99c8468-edb0-47db-b33c-110129d2d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate\n",
    "\n",
    "def cross_correlation(a, b, max_lag=10):\n",
    "    assert len(a) == len(b)\n",
    "    a = a - np.mean(a)\n",
    "    b = b - np.mean(b)\n",
    "    corr = correlate(a, b, mode='full')\n",
    "    lags = np.arange(-len(a) + 1, len(a))\n",
    "    center = len(a) - 1\n",
    "    lag_range = range(center - max_lag, center + max_lag + 1)\n",
    "    return lags[lag_range], corr[lag_range]\n",
    "\n",
    "# Parameters\n",
    "n_permutations = 500\n",
    "max_lag = 10\n",
    "\n",
    "results = {\n",
    "    \"Lags\": [],\n",
    "    \"Correlations\": [],\n",
    "    \"P_Values\": []\n",
    "}\n",
    "\n",
    "for i in len(subject_list):\n",
    "    transition_vector = transitions_list[i]\n",
    "    transition_vector = np.array(transition_vector)\n",
    "    event_vector = np.array(event_boundaries)\n",
    "\n",
    "    # True correlation\n",
    "    lags, true_corr = cross_correlation(transition_vector, event_vector, max_lag=max_lag)\n",
    "\n",
    "    # Null distribution via circular shift\n",
    "    null_corrs = np.zeros((n_permutations, len(true_corr)))\n",
    "\n",
    "    for p in range(n_permutations):\n",
    "        shift_amount = np.random.randint(1, len(event_vector))  # exclude 0 shift\n",
    "        shifted = np.roll(event_vector, shift_amount)\n",
    "        _, permuted_corr = cross_correlation(transition_vector, shifted, max_lag=max_lag)\n",
    "        null_corrs[p] = permuted_corr\n",
    "\n",
    "    # Compute two-tailed p-values\n",
    "    p_vals = np.mean(np.abs(null_corrs) >= np.abs(true_corr), axis=0)\n",
    "\n",
    "    # Store results\n",
    "    results[\"Lags\"].append(lags)\n",
    "    results[\"Correlations\"].append(true_corr)\n",
    "    results[\"P_Values\"].append(p_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4422ef-2137-45cf-8d98-e2f26f3e7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Flatten all p-values to correct across all subjects Ã— lags\n",
    "all_pvals = np.concatenate(results[\"P_Values\"])\n",
    "_, pvals_fdr, _, _ = multipletests(all_pvals, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "# Store FDR-corrected p-values back into results\n",
    "fdr_corrected = np.split(pvals_fdr, len(subject_list))\n",
    "results[\"P_Values_FDR\"] = fdr_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26d7a9-78db-415e-8277-a8167fea7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_results = []\n",
    "for subj, (lags, corrs, raw_p, fdr_p) in enumerate(zip(\n",
    "        results[\"Lags\"], results[\"Correlations\"], results[\"P_Values\"], results[\"P_Values_FDR\"])):\n",
    "    for lag, corr, p, pfdr in zip(lags, corrs, raw_p, fdr_p):\n",
    "        flat_results.append({\n",
    "            \"Subject\": subj + 1,\n",
    "            \"Lag\": lag,\n",
    "            \"Correlation\": corr,\n",
    "            \"P_Value\": p,\n",
    "            \"P_Value_FDR\": pfdr\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(flat_results)\n",
    "\n",
    "# Add significance flag for coloring\n",
    "df[\"Significant\"] = df[\"P_Value_FDR\"] < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c83d4f-cb2d-4f54-ac28-00499385f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot with x jitter and exact y-values\n",
    "sns.stripplot(\n",
    "    data=df,\n",
    "    x=\"Lag\",\n",
    "    y=\"Correlation\",\n",
    "    hue=\"Significant\",\n",
    "    palette={True: \"red\", False: \"gray\"},\n",
    "    dodge=False,\n",
    "    jitter=0.2,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.title(\"Cross-Correlation Across Lags with FDR-Corrected Significance\")\n",
    "plt.xlabel(\"Lag\")\n",
    "plt.ylabel(\"Cross-Correlation\")\n",
    "plt.legend(title=\"FDR Significant\", loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
